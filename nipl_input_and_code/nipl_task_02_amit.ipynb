{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a946b3",
   "metadata": {},
   "source": [
    "## Import some required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7503ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# import traceback\n",
    "import re\n",
    "# import os\n",
    "# import json\n",
    "# import pickle\n",
    "# import glob\n",
    "# from PIL import Image\n",
    "# from time import time\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # import cv2\n",
    "# import numpy as np\n",
    "# from numpy import array\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from tensorflow import keras\n",
    "# import tensorflow as tf\n",
    "# import tensorflow.compat.v1\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# from tensorflow.keras import utils\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.merge import add\n",
    "# from keras.preprocessing import image\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.layers.wrappers import Bidirectional\n",
    "# from keras.layers.merge import add\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from keras.preprocessing import sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.layers import (Attention, Layer,\n",
    "#                                      Add,concatenate,\n",
    "#                                      Input, \n",
    "#                                      Dense,  \n",
    "#                                      LSTM, Bidirectional, GRU,\n",
    "#                                      ZeroPadding2D, \n",
    "#                                      Convolution2D, Conv2D, \n",
    "#                                      GlobalAveragePooling2D, GlobalAvgPool2D, GlobalMaxPooling2D, GlobalMaxPool2D, \n",
    "#                                      AveragePooling2D, AvgPool2D, MaxPooling2D, MaxPool2D,\n",
    "#                                      Flatten,\n",
    "#                                      BatchNormalization, \n",
    "#                                      Dropout)\n",
    "\n",
    "# from tensorflow.keras.layers import (Activation, \n",
    "#                                      ReLU, \n",
    "#                                      LeakyReLU, \n",
    "#                                      Softmax)\n",
    "\n",
    "# from tensorflow.keras.optimizers import (SGD,\n",
    "#                                          Adam,\n",
    "#                                          Adagrad,\n",
    "#                                          Adadelta,\n",
    "#                                          RMSprop,\n",
    "#                                          Nadam)\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "\n",
    "# # from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# # import pyphen\n",
    "# import eng_to_ipa as ipa  # international phonetic aphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc312e",
   "metadata": {},
   "source": [
    "## 01 First Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ef864",
   "metadata": {},
   "source": [
    "### 1.1 Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e17824",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ml.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fdb5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all html tages, digits and all special character\n",
    "pattern = [r\"<.*>\", r\"\\d\", r\"[^a-zA-Z_ ]\"]\n",
    "for pat in pattern:\n",
    "    data = re.sub(pat, \"\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae94372",
   "metadata": {},
   "source": [
    "### 1.2 Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50bcd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into lowercase\n",
    "data = data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99417f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of uniqque words in a dictionary 1504\n"
     ]
    }
   ],
   "source": [
    "count_dictionary = {}\n",
    "for ele in data.split():\n",
    "    if count_dictionary.get(ele) is None:\n",
    "        count_dictionary[ele] = 0\n",
    "    count_dictionary[ele] += 1\n",
    "print(f\"Total no. of uniqque words in a dictionary {len(count_dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a9c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "the         283\n",
       "of          191\n",
       "a           185\n",
       "to          160\n",
       "learning    149\n",
       "and         135\n",
       "in          127\n",
       "is          106\n",
       "data         77\n",
       "that         72"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = pd.DataFrame(pd.Series(count_dictionary), columns=[\"count\"]).sort_values(by=\"count\", ascending=False)\n",
    "result1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa85da42",
   "metadata": {},
   "source": [
    "### 1.3 Load : Write data provided by transformer into another output file in a different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e816497",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv(r\"..\\nipl\\ouput_task2_nipl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd08855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
